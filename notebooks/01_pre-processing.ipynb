{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check length in each folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import pillow_heif\n",
    "import sys\n",
    "\n",
    "# Get the project root\n",
    "project_root = os.path.abspath(\"..\")    # Go up one level from \"notebooks/\"\n",
    "sys.path.append(project_root)           # Add the root to the path\n",
    "\n",
    "from src.data.process_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of folders: 27\n"
     ]
    }
   ],
   "source": [
    "directory_path = os.path.join(os.getcwd(), '../', 'data', 'raw')\n",
    "folders = os.listdir(directory_path)\n",
    "\n",
    "print(f\"Length of folders: {len(folders)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-] Folder: Armando García - 195 images\n",
      "[-] Folder: Armando Islas - 103 images\n",
      "[+] Folder: Carlos Aguilar - 200 images\n",
      "[+] Folder: Cinthya Sánchez - 202 images\n",
      "[+] Folder: Daniela Flores - 201 images\n",
      "[-] Folder: Diego Rodriguez - 119 images\n",
      "[+] Folder: Ernesto Rosales - 203 images\n",
      "[+] Folder: Evelyn Escudero - 201 images\n",
      "[+] Folder: Fernando Carmona - 202 images\n",
      "[-] Folder: Galo Ayala - 175 images\n",
      "[+] Folder: Gerardo Martínez - 200 images\n",
      "[-] Folder: Isaac Saenz - 191 images\n",
      "[+] Folder: Ismael Arista - 227 images\n",
      "[+] Folder: JESSICA JUAREZ - 200 images\n",
      "[+] Folder: Jesus Soria - 200 images\n",
      "[+] Folder: Jorge Orozco - 200 images\n",
      "[-] Folder: José Piña - 181 images\n",
      "[-] Folder: Marlene Vazquez - 196 images\n",
      "[+] Folder: Mauricio Cortes - 202 images\n",
      "[+] Folder: Natalia Anaya - 201 images\n",
      "[-] Folder: Oscar Espinosa Berrueco - 199 images\n",
      "[-] Folder: Rafael Díaz - 72 images\n",
      "[+] Folder: Romario Reyes - 200 images\n",
      "[+] Folder: Santiago Barranco - 200 images\n",
      "[-] Folder: Sergio Gutierrez - 197 images\n",
      "[-] Folder: Uriel Martinez - 126 images\n",
      "[+] Folder: Yahir Arias - 205 images\n"
     ]
    }
   ],
   "source": [
    "for folder in folders:\n",
    "    folder_path = os.path.join(directory_path, folder)\n",
    "    images = os.listdir(folder_path)\n",
    "    if len(images) >= 200:\n",
    "        print(f\"[+] Folder: {folder} - {len(images)} images\")\n",
    "    else:\n",
    "        print(f\"[-] Folder: {folder} - {len(images)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change folders names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get names of folders in the directory\n",
    "directory_path = os.path.join(os.getcwd(), '../', 'data', 'raw')\n",
    "folders = os.listdir(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_folders = [normalize_folder_name(folder) for folder in folders]\n",
    "\n",
    "for folder, new_folder in zip(folders, normalize_folders):\n",
    "    os.rename(os.path.join(directory_path, folder), os.path.join(directory_path, new_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check image format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available image formats\n",
    "pillow_heif.register_heif_opener()\n",
    "\n",
    "directory_path = os.path.join(os.getcwd(), 'images')\n",
    "folders = os.listdir(directory_path)\n",
    "\n",
    "# Check image format in each folder\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(directory_path, folder)\n",
    "\n",
    "    # Skip if it's not a folder\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "\n",
    "    images = os.listdir(folder_path)\n",
    "    for image_name in images:\n",
    "        image_path = os.path.join(folder_path, image_name)\n",
    "        try:\n",
    "            with Image.open(image_path) as img:\n",
    "                pass\n",
    "                # print(f\"[+] Image '{image_name}' in folder '{folder}' is readable.\")\n",
    "        except Exception as e:\n",
    "            print(f\"[-] Failed to read image '{image_name}' in folder '{folder}': {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename and rezise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get names of folders in the directory\n",
    "\n",
    "directory_path = os.path.join(os.getcwd(), 'images')\n",
    "folders_images = os.listdir(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_with_padding(image, target_size):\n",
    "    old_size = image.size  # (width, height) in Pillow\n",
    "    ratio = float(target_size) / max(old_size)\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])\n",
    "\n",
    "    resized_img = image.resize(new_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "    delta_w = target_size - new_size[0]\n",
    "    delta_h = target_size - new_size[1]\n",
    "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "\n",
    "    # New image with white background\n",
    "    new_img = Image.new(\"RGB\", (target_size, target_size), (0, 0, 0))\n",
    "    new_img.paste(resized_img, (left, top))\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes de alexia_cruces: 100%|██████████| 211/211 [00:23<00:00,  9.05it/s]\n",
      "Procesando imágenes de armando_garcia: 100%|██████████| 195/195 [00:48<00:00,  3.98it/s]\n",
      "Procesando imágenes de armando_islas: 100%|██████████| 103/103 [00:06<00:00, 16.91it/s]\n",
      "Procesando imágenes de carlos_aguilar: 100%|██████████| 200/200 [00:18<00:00, 10.89it/s]\n",
      "Procesando imágenes de cinthya_sanchez: 100%|██████████| 202/202 [00:46<00:00,  4.31it/s]\n",
      "Procesando imágenes de daniela_flores: 100%|██████████| 201/201 [00:35<00:00,  5.74it/s]\n",
      "Procesando imágenes de diego_rodriguez: 100%|██████████| 119/119 [00:26<00:00,  4.46it/s]\n",
      "Procesando imágenes de ernesto_rosales: 100%|██████████| 202/202 [00:43<00:00,  4.67it/s]\n",
      "Procesando imágenes de evelyn_escudero: 100%|██████████| 203/203 [00:07<00:00, 26.57it/s]\n",
      "Procesando imágenes de fernando_carmona: 100%|██████████| 206/206 [00:31<00:00,  6.47it/s]\n",
      "Procesando imágenes de gerardo_martinez: 100%|██████████| 200/200 [00:54<00:00,  3.69it/s]\n",
      "Procesando imágenes de isaac_saenz: 100%|██████████| 180/180 [00:21<00:00,  8.52it/s]\n",
      "Procesando imágenes de ismael_arista: 100%|██████████| 66/66 [00:09<00:00,  7.31it/s]\n",
      "Procesando imágenes de jessica_juarez: 100%|██████████| 200/200 [00:22<00:00,  8.83it/s]\n",
      "Procesando imágenes de jorge_orozco: 100%|██████████| 200/200 [00:09<00:00, 20.67it/s]\n",
      "Procesando imágenes de jose_pina: 100%|██████████| 172/172 [00:09<00:00, 18.57it/s]\n",
      "Procesando imágenes de marlene_vazquez: 100%|██████████| 123/123 [00:18<00:00,  6.53it/s]\n",
      "Procesando imágenes de mauricio_cortes: 100%|██████████| 117/117 [00:07<00:00, 15.67it/s]\n",
      "Procesando imágenes de natalia_anaya: 100%|██████████| 156/156 [00:09<00:00, 16.76it/s]\n",
      "Procesando imágenes de oscar_espinosa_berrueco: 100%|██████████| 199/199 [00:40<00:00,  4.89it/s]\n",
      "Procesando imágenes de rafael_diaz: 100%|██████████| 72/72 [00:02<00:00, 26.43it/s]\n",
      "Procesando imágenes de romario_reyes: 100%|██████████| 200/200 [00:07<00:00, 27.35it/s]\n",
      "Procesando imágenes de santiago_barranco: 100%|██████████| 200/200 [00:42<00:00,  4.74it/s]\n",
      "Procesando imágenes de sergio_gutierrez: 100%|██████████| 131/131 [00:15<00:00,  8.73it/s]\n",
      "Procesando imágenes de uriel_martinez: 100%|██████████| 126/126 [00:18<00:00,  6.75it/s]\n"
     ]
    }
   ],
   "source": [
    "for folder in folders_images:\n",
    "    # --> Read images in the folder\n",
    "    folder_path = os.path.join(directory_path, folder)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "\n",
    "    images = os.listdir(folder_path)\n",
    "    counter = 1\n",
    "\n",
    "    for image in tqdm(images, desc=f\"Procesando imágenes de {folder}\"):\n",
    "        image_path = os.path.join(folder_path, image)\n",
    "        try:\n",
    "            # --> Open image\n",
    "            img = Image.open(image_path)\n",
    "\n",
    "            # --> Resize image\n",
    "            resized_img = resize_with_padding(img, 224)\n",
    "\n",
    "            # --> Define new name and path\n",
    "            new_name = f\"{folder}_{counter}.jpg\"\n",
    "            new_path = os.path.join(folder_path, new_name)\n",
    "\n",
    "            # --> Save image\n",
    "            resized_img.save(new_path, \"JPEG\")\n",
    "\n",
    "            # --> Remove old image\n",
    "            if image != new_name:\n",
    "                os.remove(image_path)\n",
    "            counter += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error en la imagen {image}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split images into train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enviando imágenes de uriel_martinez: 100%|██████████| 25/25 [00:04<00:00,  5.21it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "for folder in tqdm(folders, desc=f\"Enviando imágenes de {folder}\"):\n",
    "    folder_path = os.path.join(directory_path, folder)\n",
    "    images = os.listdir(folder_path)\n",
    "\n",
    "    # Split the images\n",
    "    train, temp = train_test_split(images, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Split the temp into validation and test\n",
    "    val, test = train_test_split(temp, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Create the path to train\n",
    "    train_path = os.path.join(os.getcwd(), f'dataset\\\\train\\\\{folder}')\n",
    "    os.makedirs(train_path, exist_ok=True)\n",
    "\n",
    "    # Create the path to validation\n",
    "    val_path = os.path.join(os.getcwd(), f'dataset\\\\val\\\\{folder}')\n",
    "    os.makedirs(val_path, exist_ok=True)\n",
    "\n",
    "    # Create the path to test\n",
    "    test_path = os.path.join(os.getcwd(), f'dataset\\\\test\\\\{folder}')\n",
    "    os.makedirs(test_path, exist_ok=True)\n",
    "\n",
    "    # Move the images to folder train\n",
    "    for image in train:\n",
    "        image_path = os.path.join(folder_path, image)\n",
    "        new_path = os.path.join(train_path, image)\n",
    "        os.rename(image_path, new_path)\n",
    "\n",
    "    # Move the images to folder val\n",
    "    for image in val:\n",
    "        image_path = os.path.join(folder_path, image)\n",
    "        new_path = os.path.join(val_path, image)\n",
    "        os.rename(image_path, new_path)\n",
    "\n",
    "    # Move the images to folder test\n",
    "    for image in test:\n",
    "        image_path = os.path.join(folder_path, image)\n",
    "        new_path = os.path.join(test_path, image)\n",
    "        os.rename(image_path, new_path)\n",
    "\n",
    "    # Delete the folder\n",
    "    os.rmdir(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - alexia_cruces: 168 images\n",
      "Train - armando_garcia: 156 images\n",
      "Train - armando_islas: 82 images\n",
      "Train - carlos_aguilar: 160 images\n",
      "Train - cinthya_sanchez: 161 images\n",
      "Train - daniela_flores: 160 images\n",
      "Train - diego_rodriguez: 95 images\n",
      "Train - ernesto_rosales: 161 images\n",
      "Train - evelyn_escudero: 162 images\n",
      "Train - fernando_carmona: 164 images\n",
      "Train - gerardo_martinez: 160 images\n",
      "Train - isaac_saenz: 144 images\n",
      "Train - ismael_arista: 52 images\n",
      "Train - jessica_juarez: 160 images\n",
      "Train - jorge_orozco: 160 images\n",
      "Train - jose_pina: 137 images\n",
      "Train - marlene_vazquez: 98 images\n",
      "Train - mauricio_cortes: 93 images\n",
      "Train - natalia_anaya: 124 images\n",
      "Train - oscar_espinosa_berrueco: 159 images\n",
      "Train - rafael_diaz: 57 images\n",
      "Train - romario_reyes: 160 images\n",
      "Train - santiago_barranco: 160 images\n",
      "Train - sergio_gutierrez: 104 images\n",
      "Train - uriel_martinez: 100 images\n"
     ]
    }
   ],
   "source": [
    "# See distribution of images in each folder\n",
    "test_path = os.path.join(os.getcwd(), 'dataset', 'test')\n",
    "train_path = os.path.join(os.getcwd(), 'dataset', 'train')\n",
    "val_path = os.path.join(os.getcwd(), 'dataset', 'val')\n",
    "\n",
    "test_folders = os.listdir(test_path)\n",
    "train_folders = os.listdir(train_path)\n",
    "val_folders = os.listdir(val_path)\n",
    "\n",
    "for folder in train_folders:\n",
    "    folder_path = os.path.join(train_path, folder)\n",
    "    images = os.listdir(folder_path)\n",
    "    print(f\"Train - {folder}: {len(images)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - alexia_cruces: 22 images\n",
      "Test - armando_garcia: 20 images\n",
      "Test - armando_islas: 11 images\n",
      "Test - carlos_aguilar: 20 images\n",
      "Test - cinthya_sanchez: 21 images\n",
      "Test - daniela_flores: 21 images\n",
      "Test - diego_rodriguez: 12 images\n",
      "Test - ernesto_rosales: 21 images\n",
      "Test - evelyn_escudero: 21 images\n",
      "Test - fernando_carmona: 21 images\n",
      "Test - gerardo_martinez: 20 images\n",
      "Test - isaac_saenz: 18 images\n",
      "Test - ismael_arista: 7 images\n",
      "Test - jessica_juarez: 20 images\n",
      "Test - jorge_orozco: 20 images\n",
      "Test - jose_pina: 18 images\n",
      "Test - marlene_vazquez: 13 images\n",
      "Test - mauricio_cortes: 12 images\n",
      "Test - natalia_anaya: 16 images\n",
      "Test - oscar_espinosa_berrueco: 20 images\n",
      "Test - rafael_diaz: 8 images\n",
      "Test - romario_reyes: 20 images\n",
      "Test - santiago_barranco: 20 images\n",
      "Test - sergio_gutierrez: 14 images\n",
      "Test - uriel_martinez: 13 images\n"
     ]
    }
   ],
   "source": [
    "for folder in test_folders:\n",
    "    folder_path = os.path.join(test_path, folder)\n",
    "    images = os.listdir(folder_path)\n",
    "    print(f\"Test - {folder}: {len(images)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val - alexia_cruces: 21 images\n",
      "Val - armando_garcia: 19 images\n",
      "Val - armando_islas: 10 images\n",
      "Val - carlos_aguilar: 20 images\n",
      "Val - cinthya_sanchez: 20 images\n",
      "Val - daniela_flores: 20 images\n",
      "Val - diego_rodriguez: 12 images\n",
      "Val - ernesto_rosales: 20 images\n",
      "Val - evelyn_escudero: 20 images\n",
      "Val - fernando_carmona: 21 images\n",
      "Val - gerardo_martinez: 20 images\n",
      "Val - isaac_saenz: 18 images\n",
      "Val - ismael_arista: 7 images\n",
      "Val - jessica_juarez: 20 images\n",
      "Val - jorge_orozco: 20 images\n",
      "Val - jose_pina: 17 images\n",
      "Val - marlene_vazquez: 12 images\n",
      "Val - mauricio_cortes: 12 images\n",
      "Val - natalia_anaya: 16 images\n",
      "Val - oscar_espinosa_berrueco: 20 images\n",
      "Val - rafael_diaz: 7 images\n",
      "Val - romario_reyes: 20 images\n",
      "Val - santiago_barranco: 20 images\n",
      "Val - sergio_gutierrez: 13 images\n",
      "Val - uriel_martinez: 13 images\n"
     ]
    }
   ],
   "source": [
    "for folder in val_folders:\n",
    "    folder_path = os.path.join(val_path, folder)\n",
    "    images = os.listdir(folder_path)\n",
    "    print(f\"Val - {folder}: {len(images)} images\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
